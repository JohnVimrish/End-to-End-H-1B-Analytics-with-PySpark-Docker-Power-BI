class JsonTagVariables ():
    @classmethod
    def initialize_json_tag_variables(cls):
           
           cls.postgres_jdbc_loc = "postgres_jdbc_driver_location"
           cls.files_to_process = "etl_tables_folder_location"
           cls.writing_to_db_no_of_pp = "no_parallel_processing_writing_to_tables"
           cls.memory_cache = "memory-caching"
           cls.pipeline_name = "pipeline_name"
           cls.repartition_spark_dft = "repartition_spark_dataframe" 
           cls.rmv_sprk_dft_col_starging_with  = "remove_spark_columns_starting_with"
           cls.tables_input_folder_location  = "tables_input_folder_location" 
           cls.target_db = "my_target_database"
           cls.target_db_host = "host"
           cls.target_db_port = "port"
           cls.target_db_dbname = "database_name"
           cls.target_db_user = "user"
           cls.target_db_password = "password"
           cls.target_db_driver = "driver"
           cls.target_db_database_from = "database_from"
           cls.target_db_max_open_connection_pool_number = "max_open_connection_pool_number"
           cls.sp_conf_app_name   =   "spark-configurations>>app-name"
           cls.sp_conf_master     = "spark-configurations>>master"
           cls.sp_conf_driver_memory   = "spark-configurations>>driver-memory"
           cls.sp_conf_ui_port = "spark-configurations>>ui-port"
           cls.sp_conf_executor_memory  = "spark-configurations>>executor-memory"
           cls.sp_conf_driver_cores   =  "spark-configurations>>driver-cores"
           cls.sp_conf_executor_cores   =  "spark-configurations>>executor-cores"
           cls.sp_conf_executor_instances   = "spark-configurations>>executor-instances"
           cls.sp_conf_parallelism   = "spark-configurations>>parallelism"
           cls.sp_conf_shuffle_partitions   = "spark-configurations>>shuffle-partitions"
           cls.sp_conf_task_cpus   = "spark-configurations>>task-cpus"
           cls.sp_conf_memory_fraction   = "spark-configurations>>memory-fraction" 
           cls.sp_conf_memory_storage_fraction   = "spark-configurations>>memory-storagefraction"
           cls.sp_conf_serializer   = "spark-configurations>>serializer"
           cls.sp_conf_kryo_registration   = "spark-configurations>>kryo-registration"
           cls.sp_conf_task_kryo_classes_to_register   = "spark-configurations>>kryo-classes_to_register"
           cls.sp_conf_eventlog_enabled   = "spark-configurations>>eventlog_enabled" 
           cls.sp_conf_history_fs_logdirectory   = "spark-configurations>>history_fs_logdirectory"
           cls.sp_conf_memory_caching = "spark-configurations>>memory-caching"
           cls.sp_conf_eventlog_dir = "spark-configurations>>eventlog_dir"
           cls.sp_conf_memory_offheap_enabled = "spark-configurations>>memory-offheap-enabled"
           cls.dwh_tables_config_write_mode = "write_mode"
           cls.dwh_tables_config_target_tables_groups = "target_tables_groups"
           cls.dwh_tables_config_input_type = "input_type"
           cls.dwh_tables_config_use_dft_of = "use_dft_of"
           cls.dwh_tables_config_csv_input = "csv_input"
           cls.dwh_tables_config_multiple_table_present = "multiple_table_present"
           cls.dwh_tables_config_multiple_table_input_present = "multiple_table_input_present"
           cls.dwh_tables_config_table_mapping = "table_mapping"
           cls.dwh_tables_config_execute_prequery = "execute_prequery"
           cls.dwh_tables_config_execute_postquery = "execute_postquery"
           cls.dwh_tables_config_alias_column_names = "alias_column_names"
           cls.dwh_tables_config_alias_query = "alias_query"
           cls.dwh_tables_config_prequery = "prequery"
           cls.dwh_tables_config_postquery = "postquery"
           cls.dwh_tables_config_xlsx_input_sheet = "sheet"
           cls.dwh_tables_config_xlsx_input = "excel_input"
           cls.dwh_tables_config_xlsx_input_usecols = "usecols"
           cls.dwh_tables_config_xlsx_input_table_mapping = "table_mapping"